# 02. 데이터 흐름 (Data Flow)

## 1. 로컬 추론 모드 (현재 MVP)

1.  **앱 초기화**: 사용자가 앱에 접속합니다. 서비스 워커(`sw.js`)가 앱의 주요 에셋을 캐싱합니다.
2.  **모델 로딩**:
    *   사용자가 '모델 초기화' 버튼을 클릭합니다.
    *   `use-local-chat` 훅이 `@mlc-ai/web-llm` 엔진을 초기화하고, 선택된 LLM 모델(예: Llama 3.1 8B)을 사용자의 브라우저 캐시에 다운로드합니다.
    *   UI는 다운로드 및 초기화 진행 상태를 실시간으로 표시합니다.
3.  **대화 시작 및 응답 생성**:
    *   사용자가 메시지를 입력하고 전송합니다.
    *   `use-local-chat` 훅이 입력 메시지와 이전 대화 기록을 `web-llm` 엔진에 전달합니다.
    *   엔진은 브라우저 내에서 AI 응답을 스트리밍 방식으로 생성합니다.
    *   생성되는 텍스트 토큰은 실시간으로 UI에 렌더링됩니다.
4.  **대화 기록 저장**:
    *   모든 대화(사용자, 어시스턴트)는 `localStorage`에 JSON 형태로 즉시 저장됩니다.
    *   사용자가 앱을 새로고침하거나 재방문해도 이전 대화 기록이 유지됩니다.

## 2. 클라우드 연동 모드 (향후 확장)

1.  **사용자 인증**:
    *   사용자가 구글 등으로 로그인/회원가입을 시도합니다.
    *   프론트엔드는 Supabase Auth와 통신하여 인증을 처리하고 세션을 관리합니다.
2.  **대화 시작 및 응답 생성**:
    *   사용자가 메시지를 입력합니다.
    *   프론트엔드는 인증된 사용자의 정보와 메시지를 내부 API (예: `/api/chat`)로 전송합니다.
    *   백엔드(서버리스 함수 등)는 요청을 받아 사용자 설정에 맞는 클라우드 LLM(OpenAI 등) API를 호출합니다.
    *   LLM API로부터 받은 응답을 다시 프론트엔드로 스트리밍합니다.
3.  **대화/설정 저장**:
    *   모든 대화 기록, 프롬프트, 사용자 설정 등은 Supabase(Postgres) 데이터베이스에 저장됩니다.
    *   로컬 DB(`IndexedDB`)와 클라우드 DB 간의 동기화 로직을 통해 기기 간 데이터 일관성을 유지합니다.
4.  **파일 업로드/다운로드**:
    *   사용자가 파일을 업로드하면 프론트엔드는 Supabase Storage에 직접 파일을 업로드하고, 메타데이터는 Postgres DB에 저장합니다.
